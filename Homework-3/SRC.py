# -*- coding: utf-8 -*-
"""SRC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qgydo7nOOc6-JqDMkA8LXAC34GYima-S
"""

# Mount drive
from google.colab import drive
drive.mount('/content/drive')

# Libraries
import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model,Sequential
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM,Bidirectional,Embedding,Dense,Input
from sklearn.metrics import confusion_matrix, classification_report
from keras.utils import to_categorical
from sklearn.utils import class_weight

# loading the training corpus
import re
def load_corpus(path):
    relations = {}
    with open(path) as f:
        raw = f.read()
        raw = raw.split('\t')
        #rint(raw[-10:])
        for text_block in raw:
            if len(text_block)>1:
                lines = text_block.split('\n')
                #print(lines)
                sentence = re.sub(r'<e1>(.*?)<\/e1>', r'\1', lines[0])
                sentence = re.sub(r'<e2>(.*?)<\/e2>', r'\1', sentence)
                #sentence = sentence[1:-1]
                relation = lines[1]
                #print(f"{sentence}: {relation}")
                if relation[:-7] in ["Cause-Effect", "Component-Whole", "Product-Producer", "Instrument-Agency"]:
                    relations[sentence] = relation
                else:
                    relations[sentence] = "Other-Relation"
    return relations

path = "/content/drive/MyDrive/SemEval2010_task8_all_data/SemEval2010_task8_training/TRAIN_FILE.TXT"
sentence_relation = load_corpus(path)

# Vocabulary and tags
relation_tags = list(set(list(sentence_relation.values())))
unique_words = set()
max_sentence_len = -1
for sentence in sentence_relation.keys():
    words = sentence.split()
    if len(words)>max_sentence_len:
        max_sentence_len = len(words)
    for word in words:
        unique_words.add(word.lower())
print("Length of the longest sentence: ", max_sentence_len)
print("Total Unique words:", len(unique_words))

from collections import Counter
# function to get the frequency plot for labels in data
def freq_plot(vals):
    counts = Counter(vals)
    plt.bar(counts.keys(), counts.values(),color='black')
    plt.ylabel('Frequency')
    plt.xticks(rotation=90)
    plt.show()

# Frequency plot for the all the labels in the entire training dataset
all_labels = list(sentence_relation.values())
print("Frequency plot for the entire training dataset")
freq_plot(all_labels)

# Function to print the Label Distribution for a dataset
def label_distribution(vals):
    counts = Counter(vals)
    counts = dict(counts)
    total_relations = sum(counts.values())
    stats = []
    for relation, freq in counts.items():
        percentage = (freq / total_relations) * 100
        count = freq
        stats.append((relation, percentage, count))
    print()
    print(f"{'Relation type':<25} {'Percentage':} {'Count':>10}")
    for relation, percentage, count in stats:
        print(f"{relation:<25} {percentage:<.2f}% {count:>14}")
    print("\nTotal number of relations: {}".format(total_relations))

# Label distribution for the entire training dataset
print("Label distribution for the entire training dataset")
label_distribution(all_labels)

# Splitting the "sentence-relation" pairs into train-set and validation-set
sentences = list(sentence_relation.keys())
labels = list(sentence_relation.values())
train_sentences, test_sentences, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)

# frequency plot for the train-set split 
print("Frequency plot for the train-set split")
freq_plot(train_labels)
print()
# Label distribution for the train-set split
print("Label distribution for the train-set split")
label_distribution(train_labels)

# frequency plot for the validation-set split 
print("Frequency plot for the validation-set split")
freq_plot(test_labels)
print()
# Label distribution for the validation-set split
print("Label distribution for the validation-set split")
label_distribution(test_labels)

# Function to change labels for tokenizing
# Issue: Strings of the form 'Product-Producer(e2,e1)' get split into multiple tokens which creates non-uniform data, there the below renaming is used to ensure that the Lables are uniformly tokenized
def change_labels(labels):
    renamed = []
    label_ref = {'Product-Producer(e2,e1)':'Producer-Product', 'Instrument-Agency(e2,e1)':'Agency-Instrument', 'Cause-Effect(e1,e2)':'Cause-Effect', 'Product-Producer(e1,e2)':'Product-Producer', 'Component-Whole(e1,e2)':'Component-Whole', 'Component-Whole(e2,e1)':'Whole-Component', 'Cause-Effect(e2,e1)':'Effect-Cause', 'Instrument-Agency(e1,e2)':'Instrument-Agency'}
    for i in range(len(labels)):
        if labels[i] != 'Other-Relation':
            renamed.append(label_ref[labels[i]])
        else:
            renamed.append('Other-Relation')
    return renamed

# Tokeinzing the training sentences split from the training data
sentence_tokenizer = Tokenizer(20000, lower=True)
sentence_tokenizer.fit_on_texts(train_sentences)
encoded_train_sentences = sentence_tokenizer.texts_to_sequences(train_sentences)
encoded_validation_sentence = sentence_tokenizer.texts_to_sequences(test_sentences)

renamed_train_labels = change_labels(train_labels)
renamed_test_labels = change_labels(test_labels)

labels_tokenizer = Tokenizer(filters='!"#$%&()*+,./:;<=>?@[\\]^_`{|}~\t\n')
labels_tokenizer.fit_on_texts(renamed_train_labels)
encoded_train_labels = labels_tokenizer.texts_to_sequences(renamed_train_labels)
encoded_train_labels = [[label[0]-1] for label in encoded_train_labels]
encoded_validation_labels = labels_tokenizer.texts_to_sequences(renamed_test_labels)
encoded_validation_labels = [[label[0]-1] for label in encoded_validation_labels]

# Padding the sentences after tokenizing
X_train = pad_sequences(encoded_train_sentences, maxlen = 100, truncating='post')
X_test= pad_sequences(encoded_validation_sentence, maxlen = 100, truncating='post')

#encoded_train_labels[:10]
classes_num = len(set(renamed_train_labels))
y_train = to_categorical(encoded_train_labels,num_classes=classes_num)
y_test = to_categorical(encoded_validation_labels,num_classes=classes_num)

X_train.shape, y_test.shape

# Model Definition
embedding_size = 300
model = Sequential()
model.add(Embedding(20000, embedding_size, input_length=X_train.shape[1]))
model.add(Bidirectional(LSTM(512, dropout=0.8, recurrent_dropout=0.8)))
model.add(Dense(y_train.shape[1], activation='softmax'))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])
print(model.summary())

"""**The following block is for Model Improvement by Balancing the training data**\
**Using appropriate class during model training the skew in data was tackled**\
**class weights using scikit-learn's `compute_class_weight` function.**

"""

categorical_train_labels = [l[0] for l in encoded_train_labels]
categorical_freq = np.bincount(categorical_train_labels)
class_weights = class_weight.compute_class_weight(class_weight = 'balanced',classes = np.unique(categorical_train_labels), y=categorical_train_labels)
model_weights = dict(enumerate(class_weights))
print(model_weights)
Model = model.fit(X_train, y_train, epochs=14, batch_size=256, validation_data=(X_test,y_test), class_weight=model_weights)

"""**Run the below block if you want to run the model without balanced data**\
**RUN any one of your choice, as per the results you wish to observe**
"""

Model = model.fit(X_train, y_train, epochs=14, batch_size=256, validation_data=(X_test,y_test))

plt.plot(Model.history['acc'])
plt.plot(Model.history['val_acc'])
plt.title('Training V/S Validation')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'test'], loc="lower right")
plt.show()

# Validation data performance
val_out = model.predict(X_test,verbose=1)
val_predictions = [np.argmax(pred) for pred in val_out]
true_predictions = [np.argmax(true) for true in y_test]
print(classification_report(true_predictions, val_predictions))
print(confusion_matrix(true_predictions, val_predictions))

# function to load test data
def load_test_corpus(path):
    relations = {}
    with open(path) as f:
        raw = f.read()
        raw = raw.split('\t')
        for text_block in raw[1:]:
            if len(text_block)>1:
                lines = text_block.split('\n')
                sentence = re.sub(r'<e1>(.*?)<\/e1>', r'\1', lines[0])
                sentence = re.sub(r'<e2>(.*?)<\/e2>', r'\1', sentence)
                #sentence = sentence[1:-1]
                relation = lines[1]
                #print(f"{sentence}: {relation}")
                if relation[:-7] in ["Cause-Effect", "Component-Whole", "Product-Producer", "Instrument-Agency"]:
                    relations[sentence] = relation
                else:
                    relations[sentence] = "Other-Relation"
    return relations

test_file_path = "/content/drive/MyDrive/SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT"
test_sentence_relation = load_test_corpus(test_file_path)

all_test_labels = list(test_sentence_relation.values())
print("Frequency plot for the testing data")
freq_plot(all_test_labels)
print()
print("Label Distribution for the testing data")
label_distribution(all_test_labels)

# tokenize and pad test data
test_data_sentences = list(test_sentence_relation.keys())
test_data_labels = list(test_sentence_relation.values())

test_sentence_tokenizer = Tokenizer(20000, lower=True)
test_sentence_tokenizer.fit_on_texts(test_data_sentences)
encoded_test_data_sentences = test_sentence_tokenizer.texts_to_sequences(test_data_sentences)

renamed_test_data_labels = change_labels(test_data_labels)
test_labels_tokenizer = Tokenizer(filters='!"#$%&()*+,./:;<=>?@[\\]^_`{|}~\t\n')
test_labels_tokenizer.fit_on_texts(renamed_test_data_labels)
encoded_test_data_labels = test_labels_tokenizer.texts_to_sequences(renamed_test_data_labels)
encoded_test_data_labels = [[label[0]-1] for label in encoded_test_data_labels]

test_sentences_padded = pad_sequences(encoded_test_data_sentences, maxlen = 100, truncating='post')
test_labels_categorical = to_categorical(encoded_test_data_labels,num_classes=9)

test_out = model.predict(test_sentences_padded,verbose=1)
test_predictions = [np.argmax(pred) for pred in test_out]
true_predictions = [np.argmax(true) for true in test_labels_categorical]

# get label names
tags_word_index = test_labels_tokenizer.word_index
tags_index_word = {i-1: w for w, i in tags_word_index.items()}
# convert true and predicted labels to names
true_labels = [tags_index_word[np.argmax(p)] for p in test_labels_categorical]
predicted_labels = [tags_index_word[pred] for pred in test_predictions]
def rechange_labels(labels):
    renamed = []
    label_ref = {'producer-product':'Product-Producer(e2,e1)', 'agency-instrument':'Instrument-Agency(e2,e1)', 'cause-effect':'Cause-Effect(e1,e2)', 'product-producer':'Product-Producer(e1,e2)', 'component-whole':'Component-Whole(e1,e2)', 'whole-component':'Component-Whole(e2,e1)', 'effect-cause':'Cause-Effect(e2,e1)', 'instrument-agency':'Instrument-Agency(e1,e2)','other-relation':'Other-Relation'}
    for i in range(len(labels)):
        try:
            renamed.append(label_ref[labels[i]])
        except KeyError:
            print(f"Error: label {labels[i]} not found in label_ref dictionary")
    return renamed
true_labels = rechange_labels(true_labels)
predicted_labels = rechange_labels(predicted_labels)
print(classification_report(true_labels, predicted_labels))
print(confusion_matrix(true_labels, predicted_labels))

# selecting 50 random test sentences and testing the model on it
import random
random.seed(12)
random_indices = random.sample(range(len(test_labels_categorical)), k=50)
cnt = 0
for i in random_indices:
    if true_labels[i] != predicted_labels[i]:
        cnt += 1 
        print(str(i)+ ':\t'+test_data_sentences[i] + '\n' + 'True tag: '+ true_labels[i] + '\tPredicted Tag: '+ predicted_labels[i])
        print()
print()
print("Erroneous predictions: ", cnt)